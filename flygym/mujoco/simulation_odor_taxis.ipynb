{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import trange\n",
    "from flygym.mujoco.arena import OdorArena\n",
    "import matplotlib.pyplot as plt\n",
    "from flygym.mujoco import Parameters\n",
    "from flygym.mujoco.examples.turning_controller import HybridTurningNMF\n",
    "\n",
    "\n",
    "# Odor source: array of shape (num_odor_sources, 3) - xyz coords of odor sources\n",
    "odor_source = np.array([[24, 0, 1.5], [8, -4, 1.5]]) #, [16, 4, 1.5]])\n",
    "\n",
    "# Peak intensities: array of shape (num_odor_sources, odor_dimesions)\n",
    "# For each odor source, if the intensity is (x, 0) then the odor is in the 1st dimension\n",
    "# (in this case attractive). If it's (0, x) then it's in the 2nd dimension (in this case\n",
    "# aversive)\n",
    "peak_intensity = np.array([[1, 0], [0, 1]]) #, [0, 1]])\n",
    "\n",
    "# Marker colors: array of shape (num_odor_sources, 4) - RGBA values for each marker,\n",
    "# normalized to [0, 1]\n",
    "#marker_colors = [[255, 127, 14], [31, 119, 180], [31, 119, 180]]\n",
    "#marker_colors = np.array([[*np.array(color) / 255, 1] for color in marker_colors])\n",
    "\n",
    "odor_dimesions = len(peak_intensity[0])\n",
    "\n",
    "odor_valence = [1,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arena = OdorArena(\n",
    "     odor_source=odor_source,\n",
    "     peak_intensity=peak_intensity,\n",
    "     odor_valence=odor_valence,\n",
    "     diffuse_func=lambda x: x**-2,\n",
    "     marker_size=0.3,\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contact_sensor_placements = [\n",
    "    f\"{leg}{segment}\"\n",
    "    for leg in [\"LF\", \"LM\", \"LH\", \"RF\", \"RM\", \"RH\"]\n",
    "    for segment in [\"Tibia\", \"Tarsus1\", \"Tarsus2\", \"Tarsus3\", \"Tarsus4\", \"Tarsus5\"]\n",
    "]\n",
    "sim_params = Parameters(\n",
    "    timestep=1e-4,\n",
    "    render_mode=\"saved\",\n",
    "    render_playspeed=0.5,\n",
    "    render_window_size=(800, 608),\n",
    "    enable_olfaction=True,\n",
    "    enable_adhesion=True,\n",
    "    draw_adhesion=False,\n",
    "    render_camera=\"birdeye_cam\",\n",
    ")\n",
    "sim = HybridTurningNMF(\n",
    "    sim_params=sim_params,\n",
    "    arena=arena,\n",
    "    spawn_pos=(0, 0, 0.2),\n",
    "    contact_sensor_placements=contact_sensor_placements,\n",
    "    simulation_time=10\n",
    ")\n",
    "for i in range(1):\n",
    "    sim.step(np.zeros(2))\n",
    "    sim.render()\n",
    "fig, ax = plt.subplots(1, 1, figsize=(5, 4), tight_layout=True)\n",
    "ax.imshow(sim._frames[-1])\n",
    "ax.axis(\"on\")\n",
    "fig.savefig(\"./outputs/olfaction_env.png\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(sim.curr_time)\n",
    "decision_interval = 0.05\n",
    "run_time = sim.simulation_time\n",
    "num_decision_steps = int(run_time / decision_interval)\n",
    "physics_steps_per_decision_step = int(decision_interval / sim_params.timestep)\n",
    "\n",
    "obs_hist = []\n",
    "odor_history = []\n",
    "obs, _ = sim.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"def respawn(\n",
    "        self, *, seed: Optional[int] = None, options: Optional[Dict] = None\n",
    "    ) -> Tuple[ObsType, Dict[str, Any]]:\n",
    "        \n",
    "        super().reset(seed=seed)\n",
    "        self.physics.reset()\n",
    "        if np.any(self.physics.model.opt.gravity[:] - self.sim_params.gravity > 1e-3):\n",
    "            self._set_gravity(self.sim_params.gravity)\n",
    "            if self.sim_params.align_camera_with_gravity:\n",
    "                self._camera_rot = np.eye(3)\n",
    "        self.curr_time = 0\n",
    "        self._set_init_pose(self.init_pose)\n",
    "        #self._last_render_time = -np.inf\n",
    "        #self._last_vision_update_time = -np.inf\n",
    "        #self._curr_raw_visual_input = None\n",
    "        #self._curr_visual_input = None\n",
    "        #self._vision_update_mask = []\n",
    "        self._flip_counter = 0\n",
    "        return self.get_observation(), self.get_info()\"\"\"\n",
    "\n",
    "\"\"\"This is the function that I implemented in the core.py in order to respawn the fly\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_simulation(arena, sim, num_decision_steps, obs, physics_steps_per_decision_step):\n",
    "    \"\"\"if len(arena.valence_dictionary) != len(sim.fly_valence_dictionary):\n",
    "        attractive_gain, aversive_gain = arena.generate_random_gains(True)\n",
    "    else:\n",
    "        attractive_gain, aversive_gain = arena.generate_random_gains(False)\"\"\"\n",
    "    attractive_gain = -500\n",
    "    aversive_gain = 80\n",
    "    for _ in trange(num_decision_steps):\n",
    "        attractive_intensities = np.average(\n",
    "            obs[\"odor_intensity\"][0, :].reshape(2, 2), axis=0, weights=[9, 1]\n",
    "        )\n",
    "        aversive_intensities = np.average(\n",
    "            obs[\"odor_intensity\"][1, :].reshape(2, 2), axis=0, weights=[10, 0]\n",
    "        )\n",
    "        attractive_bias = (\n",
    "            attractive_gain\n",
    "            * (attractive_intensities[0] - attractive_intensities[1])\n",
    "            / attractive_intensities.mean()\n",
    "        )\n",
    "        aversive_bias = (\n",
    "            aversive_gain\n",
    "            * (aversive_intensities[0] - aversive_intensities[1])\n",
    "            / aversive_intensities.mean()\n",
    "        )\n",
    "        effective_bias = aversive_bias + attractive_bias\n",
    "        effective_bias_norm = np.tanh(effective_bias**2) * np.sign(effective_bias)\n",
    "        assert np.sign(effective_bias_norm) == np.sign(effective_bias)\n",
    "\n",
    "        control_signal = np.ones((2,))\n",
    "        side_to_modulate = int(effective_bias_norm > 0)\n",
    "        modulation_amount = np.abs(effective_bias_norm) * 0.8\n",
    "        control_signal[side_to_modulate] -= modulation_amount\n",
    "\n",
    "        for _ in range(physics_steps_per_decision_step):\n",
    "            obs, reward, terminated, truncated, _ = sim.step(control_signal)\n",
    "            rendered_img = sim.render()\n",
    "            if rendered_img is not None:\n",
    "                # record odor intensity too for video\n",
    "                odor_history.append(obs[\"odor_intensity\"])\n",
    "            obs_hist.append(obs)\n",
    "        \n",
    "            if reward != None:\n",
    "                print(\"A reward was found, let's start again exploring\")\n",
    "                _, _ = sim.respawn()\n",
    "                print(\"Elapsed time in the simulation\", sim.elapsed_time)\n",
    "                run_simulation(arena, sim, num_decision_steps, obs, physics_steps_per_decision_step)\n",
    "            if terminated:\n",
    "                print(\"Out of time\")\n",
    "                print(\"Elapsed time in the simulation\", sim.elapsed_time)\n",
    "                break\n",
    "            if truncated:\n",
    "                print(\"A reward was not found\")\n",
    "                _, _ = sim.respawn()\n",
    "                print(\"Elapsed time in the simulation\", sim.elapsed_time)\n",
    "                run_simulation(arena, sim, num_decision_steps, obs, physics_steps_per_decision_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_simulation(arena, sim, num_decision_steps, obs, physics_steps_per_decision_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fly_pos_hist = np.array([obs[\"fly\"][0, :2] for obs in obs_hist])\n",
    "fig, ax = plt.subplots(1, 1, figsize=(5, 4), tight_layout=True)\n",
    "ax.scatter(\n",
    "    [odor_source[0, 0]],\n",
    "    [odor_source[0, 1]],\n",
    "    marker=\"o\",\n",
    "    color=\"tab:orange\",\n",
    "    s=50,\n",
    "    label=\"Attractive\",\n",
    ")\n",
    "ax.scatter(\n",
    "    [odor_source[1, 0]],\n",
    "    [odor_source[1, 1]],\n",
    "    marker=\"o\",\n",
    "    color=\"tab:blue\",\n",
    "    s=50,\n",
    "    label=\"Aversive\",\n",
    ")\n",
    "#ax.scatter([odor_source[2, 0]], [odor_source[2, 1]], marker=\"o\", color=\"tab:blue\", s=50)\n",
    "ax.plot(fly_pos_hist[:, 0], fly_pos_hist[:, 1], color=\"k\", label=\"Fly trajectory\")\n",
    "ax.set_aspect(\"equal\")\n",
    "ax.set_xlim(-1, 40)\n",
    "ax.set_ylim(-5, 5)\n",
    "ax.set_xlabel(\"x (mm)\")\n",
    "ax.set_ylabel(\"y (mm)\")\n",
    "ax.legend(ncols=3, loc=\"lower center\", bbox_to_anchor=(0.5, -0.6))\n",
    "#fig.savefig(\"./outputs/odor_taxis_trajectory.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim.save_video(\"./outputs/odor_taxis_frist_try.mp4\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
